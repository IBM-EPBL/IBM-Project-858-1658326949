{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Gn-sx4I9lrn",
    "outputId": "abf91ecb-693a-4b7f-fcf9-8c5796fc3ad4"
   },
   "source": [
    "Team ID\t        :PNT2022TMID42258\n",
    "Project Name\t:Project – REAL TIME COMMUNICATION POWERED BY AI FOR SPECIALLY ABLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4D_1s-1jmW-",
    "outputId": "9cd027f0-d234-4580-9979-54bfac15338f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.10.0 in c:\\users\\pragadeswar\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator Library And Configure It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ceQniQzAxtP8"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DfQcYt03y1iC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def get_data(arg1, **kwargs):\n",
    "  tf.keras.preprocessing.image_dataset_from_directory(\n",
    "   r'C:\\Users\\pragadeswar\\Downloads\\conversation engine for deaf and dumb.zip',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ysezy-oo1W7i"
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "  tf.keras.preprocessing.image.load_img(\n",
    "    path, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hGoqYFrq2hOX"
   },
   "outputs": [],
   "source": [
    "def get_data(image_path):\n",
    "  image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "  input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "  predictions = model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uOGlgl-0VHoi"
   },
   "outputs": [],
   "source": [
    "def get_data(img):\n",
    "  tf.keras.preprocessing.image.img_to_array(img, data_format=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UD-mMN-qVSs5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img_data = np.random.random(size=(100, 100, 3))\n",
    "img = tf.keras.preprocessing.image.array_to_img(img_data)\n",
    "array = tf.keras.preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply ImageDataGenerator Functionality To Train And Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewI6Huj8eILZ",
    "outputId": "867a7458-a964-4989-b132-563bc10acfd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r\"C:\\Users\\pragadeswar\\Downloads\\conversation engine for deaf and dumb\\Dataset\\training_set\", target_size = (64, 64), batch_size = 300, class_mode = 'categorical', color_mode = 'grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEyhCyUFCbn0",
    "outputId": "04366aa9-ae99-4950-d3cd-6ed3e81a71a3"
   },
   "source": [
    "Team ID\t        :PNT2022TMID42258\n",
    "Project Name\t:Project – REAL TIME COMMUNICATION POWERED BY AI FOR SPECIALLY ABLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import The Required Model Building Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tgg86cGygEuL"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6CwXsA5FhszJ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Add The Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BJKDgUtOmTVH"
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7jRz5N8CbrE",
    "outputId": "e985196c-33a7-4347-8b78-8915730f8eda"
   },
   "source": [
    "Add The Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ePBg9JIz4FY1"
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slzgZkF1CbuD"
   },
   "source": [
    "Add The Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nIvidcyb4Xco"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dUFoXoYfuRW",
    "outputId": "cee07fdd-fe86-4027-ef44-d0723e2c05d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\pragadeswar\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set', target_size = (64, 64), batch_size = 300, class_mode = 'categorical', color_mode = 'grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-clatuH7Cbxb"
   },
   "source": [
    "Adding The Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kMOSi9gd4XgH"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation = 'relu'))\n",
    "model.add(Dense(units = 9, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "ixfyiEe0D4BD",
    "outputId": "1c74ca71-8526-431d-ef73-6b54e809ab02"
   },
   "source": [
    "Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YdyvFOCB4XkW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iA12f3yD4Ei"
   },
   "source": [
    "Fit And Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdQ405Gi4XoT",
    "outputId": "9adb6a83-9491-4572-d433-fae41683d614",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pragadeswar\\AppData\\Local\\Temp\\ipykernel_16564\\4269064847.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train, steps_per_epoch = 24, epochs = 10, validation_data = x_test, validation_steps = 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.6939WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
      "24/24 [==============================] - 91s 4s/step - loss: 1.0149 - accuracy: 0.6939 - val_loss: 0.4040 - val_accuracy: 0.8791\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 42s 2s/step - loss: 0.2250 - accuracy: 0.9357\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 26s 1s/step - loss: 0.1242 - accuracy: 0.9657\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 20s 837ms/step - loss: 0.0739 - accuracy: 0.9812\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 15s 595ms/step - loss: 0.0490 - accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 12s 509ms/step - loss: 0.0396 - accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 10s 432ms/step - loss: 0.0301 - accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 10s 423ms/step - loss: 0.0221 - accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 10s 390ms/step - loss: 0.0214 - accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 10s 386ms/step - loss: 0.0179 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2118adfff10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, steps_per_epoch = 24, epochs = 10, validation_data = x_test, validation_steps = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PvjhCBT_B8W5"
   },
   "outputs": [],
   "source": [
    "model.save('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHrKBm8tD4KQ"
   },
   "source": [
    "Test The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-hylCNND4OI"
   },
   "source": [
    "Import The Packages And Load The Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jkYAy2OkB8Z7"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fxuo9-pFB8dV"
   },
   "outputs": [],
   "source": [
    "model = load_model('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAC9klEQVR4nO2dPYsqUQyGo4hMK1iIpSAIYj+N1lrZWU4lzF+wt/AnWNn60VgLVmrhHxCmtBI7QRB0bLyFe5d7URajOck5S57OZU0y776ZyXydBVAURVEUYorF4u0vvu/7vi9dkcXcHsjlctJF/URSugCXSIlk7ff7T3/ebDaPx+P3x/F4zFWRxTw24FP2+710pf+hbYggIZL1dru9+JuJhEyFT1FnIbBdrCiKoiiSruILJpMvFgsAqNVq2C9qG7oKx5z1+u7ccmx31n3gkq7iC9vFsgqzbViv143GZ8bssYaqgyw5JmobInBDrOv1+n12HQRBEATSFVHj+/6LVxfeoNvt8m+RG86yBINirddrc8FTKYHLluosBCoWAiNmLpVKJsKKo85CYGQyvjvL9EU7/rFenYVAxUJgxMk8V6C0DRH0er1er8eZ0WGx+HG4De9wNqM6C4GKhUDFQqBiIaAXy/JHHT9BnYVAxUKgYiGgF2u1WpHHtAR1liiVSsXc7cJHODeN/sSKewP03NBOVCwEKhYCFQuB82KFYRiGIU8u58XihPL2fTL5y6WnFCudThNGe5FyucyW65d7gRbK8Zd5dv8Xnjle5rVfQpbLJVsubUMEzjtrNBqx5dJ9FgJtQwTOt+FwOGTLpc5CQOOs8/lMEucNOEcH59uQ8xxL2xABzRFXcGgoFAoAsN1uGXI5L5be3bEUGrHiOI7jmCSUzdB42PM8EBogtA0thWbOulwuJHFQdDod5ozqLCE8z/M8j+fhGeYXUe44/BSNvuhkNfRiZbNZ8piPiKxOYyTl/bJJtVo1EVxwER9tQwRG/kr5fB4AdrudieDtdhsABoOBieBiTKdT8olhPp8LbpG2IQKzO8vJZAIArVaLKqDsEm0cuUnG1NlsBgCNRuPzUG+jbWgZn+/XjS7F9TrqLARurFNqyT9OUWchULEQuCHWZrORLgHAFbFOp5N0CQCuiGUJZif4w+EAAJlM5vNQNqxF7caq3WCHWNqGCP4AG0CeSflSeSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img(r\"C:\\Users\\pragadeswar\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set\\B\\46.png\",target_size = (100,100))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Test Image, Pre-Process It And Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gF57_t2L4Xr9"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "  img=image.img_to_array(frame)\n",
    "  img = resize(frame, (64,64,1))\n",
    "  img = np.expand_dims(img, axis = 0)\n",
    "  pred=np.argmax(model.predict(img))\n",
    "  op=['A','B','C','D','E','F','G','H','I']\n",
    "  print('The predicted letter is',op[pred])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0_tIQBAV6TOW"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82dk9JEYDR2-",
    "outputId": "e6becbaf-7b46-4aee-c0b5-21708d13d93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n",
      "The predicted letter is G\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(r'C:\\Users\\pragadeswar\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set\\G\\1.png')\n",
    "data = detect(frame)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
