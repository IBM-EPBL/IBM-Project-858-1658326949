{"cells": [{"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "5Gn-sx4I9lrn", "outputId": "abf91ecb-693a-4b7f-fcf9-8c5796fc3ad4"}, "cell_type": "markdown", "source": "Team ID\t        :PNT2022TMID42258\nProject Name\t:Project \u2013 REAL TIME COMMUNICATION POWERED BY AI FOR SPECIALLY ABLED"}, {"metadata": {}, "cell_type": "markdown", "source": "Image preprocessing"}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "V4D_1s-1jmW-", "outputId": "9cd027f0-d234-4580-9979-54bfac15338f", "scrolled": false}, "cell_type": "code", "source": "!pip install keras==2.7.0", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: keras==2.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install tensorflow==2.5.0", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: tensorflow==2.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.5.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.7.4.3)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.15.0)\nRequirement already satisfied: tensorboard~=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.9.1)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.2)\nRequirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.19.1)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.37.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.19.5)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.15.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.2.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.6.3)\nRequirement already satisfied: grpcio~=1.34.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.34.1)\nRequirement already satisfied: h5py~=3.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.1.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.0)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.4.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12.1)\nRequirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.5.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.3.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.26.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.4)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.23.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.6.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (58.0.4)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.9.24)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Import ImageDataGenerator Library And Configure It"}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='jo4gIWjPHHhcIDJdqWh9bGhNZUev1BSftWVW5f8TxCix',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'aicode-donotdelete-pr-zp35pf5y2lzdrf'\nobject_key = 'conversation engine for deaf and dumb.zip'\n\nstreaming_body_3 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_3.read()),'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)\n", "execution_count": 32, "outputs": []}, {"metadata": {"id": "ceQniQzAxtP8"}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale = 1./255)", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x_train = train_datagen.flow_from_directory('/home/wsuser/work/Dataset/training_set', target_size = (64, 64), batch_size = 300, class_mode = 'categorical', color_mode = 'grayscale')\nx_test = test_datagen.flow_from_directory('/home/wsuser/work/Dataset/test_set', target_size = (64, 64), batch_size = 300, class_mode = 'categorical', color_mode = 'grayscale')", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "Found 15750 images belonging to 9 classes.\nFound 2250 images belonging to 9 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten", "execution_count": 36, "outputs": []}, {"metadata": {"id": "6CwXsA5FhszJ"}, "cell_type": "code", "source": "model = Sequential()", "execution_count": 37, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "markdown", "source": "Add The Convolution Layer"}, {"metadata": {"id": "BJKDgUtOmTVH"}, "cell_type": "code", "source": "model.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))", "execution_count": 38, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "p7jRz5N8CbrE", "outputId": "e985196c-33a7-4347-8b78-8915730f8eda"}, "cell_type": "markdown", "source": "Add The Pooling Layer"}, {"metadata": {"id": "ePBg9JIz4FY1"}, "cell_type": "code", "source": "model.add(MaxPooling2D(pool_size = (2,2)))", "execution_count": 39, "outputs": []}, {"metadata": {"id": "slzgZkF1CbuD"}, "cell_type": "markdown", "source": "Add The Flatten Layer"}, {"metadata": {"id": "nIvidcyb4Xco"}, "cell_type": "code", "source": "model.add(Flatten())", "execution_count": 40, "outputs": []}, {"metadata": {"id": "-clatuH7Cbxb"}, "cell_type": "markdown", "source": "Adding The Dense Layers"}, {"metadata": {"id": "kMOSi9gd4XgH"}, "cell_type": "code", "source": "model.add(Dense(units = 512, activation = 'relu'))\nmodel.add(Dense(units = 9, activation = 'softmax'))", "execution_count": 41, "outputs": []}, {"metadata": {"colab": {"background_save": true, "base_uri": "https://localhost:8080/", "height": 380}, "id": "ixfyiEe0D4BD", "outputId": "1c74ca71-8526-431d-ef73-6b54e809ab02"}, "cell_type": "markdown", "source": "Compile The Model"}, {"metadata": {}, "cell_type": "code", "source": "model.summary()", "execution_count": 42, "outputs": [{"output_type": "stream", "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 30752)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               15745536  \n_________________________________________________________________\ndense_3 (Dense)              (None, 9)                 4617      \n=================================================================\nTotal params: 15,750,473\nTrainable params: 15,750,473\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {"id": "YdyvFOCB4XkW"}, "cell_type": "code", "source": "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])", "execution_count": 43, "outputs": []}, {"metadata": {"id": "8iA12f3yD4Ei"}, "cell_type": "markdown", "source": "Fit And Save The Model"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "GdQ405Gi4XoT", "outputId": "9adb6a83-9491-4572-d433-fae41683d614", "scrolled": true}, "cell_type": "code", "source": "model.fit(x_train, steps_per_epoch = 24, epochs = 10, validation_data = x_test, validation_steps = 40)", "execution_count": 44, "outputs": [{"output_type": "stream", "text": "Epoch 1/10\n24/24 [==============================] - ETA: 0s - loss: 0.9221 - accuracy: 0.7138WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n24/24 [==============================] - 31s 1s/step - loss: 0.9221 - accuracy: 0.7138 - val_loss: 0.3336 - val_accuracy: 0.9040\nEpoch 2/10\n24/24 [==============================] - 28s 1s/step - loss: 0.2259 - accuracy: 0.9328\nEpoch 3/10\n24/24 [==============================] - 28s 1s/step - loss: 0.1128 - accuracy: 0.9704\nEpoch 4/10\n24/24 [==============================] - 28s 1s/step - loss: 0.0722 - accuracy: 0.9803\nEpoch 5/10\n24/24 [==============================] - 28s 1s/step - loss: 0.0516 - accuracy: 0.9862\nEpoch 6/10\n24/24 [==============================] - 28s 1s/step - loss: 0.0433 - accuracy: 0.9885\nEpoch 7/10\n24/24 [==============================] - 30s 1s/step - loss: 0.0293 - accuracy: 0.9940\nEpoch 8/10\n24/24 [==============================] - 29s 1s/step - loss: 0.0205 - accuracy: 0.9953\nEpoch 9/10\n24/24 [==============================] - 29s 1s/step - loss: 0.0180 - accuracy: 0.9951\nEpoch 10/10\n24/24 [==============================] - 28s 1s/step - loss: 0.0166 - accuracy: 0.9957\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 44, "data": {"text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb6161e0250>"}, "metadata": {}}]}, {"metadata": {"id": "PvjhCBT_B8W5"}, "cell_type": "code", "source": "model.save('aslpng1.h5')", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf image.Classification.model_new.tgz aslpng1.h5", "execution_count": 46, "outputs": [{"output_type": "stream", "text": "aslpng1.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls -1", "execution_count": 47, "outputs": [{"output_type": "stream", "text": "aslpng1.h5\r\n\u001b[0m\u001b[01;34mDataset\u001b[0m/\r\nimage.Classification.model_new.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson_machine_learning_client --upgrade", "execution_count": 48, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: watson_machine_learning_client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2022.9.24)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.8.9)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.26.0)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (4.62.3)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.3.4)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.18.21)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.26.7)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.3.3)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.10.0)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.5.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (3.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (1.19.5)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nurl_credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    #\"apikey\": \"sqLVTXSP3nnAKfzJ1rKRKCpNzS_XZ8_HXa9FRwV7BvOP\"\n    \"apikey\":  \"onrJcGGyt_7jdTqE2t4UxrWVimZMQqB6FXXqs8bpFO0D\"\n}\nclient = APIClient(url_credentials)", "execution_count": 49, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(url_credentials)", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])", "execution_count": 51, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guid_from_space_name(client, 'imageclassification')\nprint(\"space UID = \" + space_uid)", "execution_count": 52, "outputs": [{"output_type": "stream", "text": "space UID = 83bc0c10-2eea-43e5-9915-96f0fb28b425\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 53, "outputs": [{"output_type": "execute_result", "execution_count": 53, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list(800)", "execution_count": 54, "outputs": [{"output_type": "stream", "text": "-------------------------------  ------------------------------------  ----\nNAME                             ASSET_ID                              TYPE\ndefault_py3.6                    0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12        020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt       069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6          09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12       09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9        0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6            0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                       0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod     1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6                10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl        111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10          125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9               12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6          154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                     1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6           1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6             1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt    1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6             1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                  20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod     217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda          26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                         295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8              2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6            2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9            2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6                2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                  2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt       32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37             36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                  390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10          396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6               39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt       40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10       40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                  41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9           4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                   42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                     493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6            49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6               4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6           50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8              52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11       55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                  5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                   5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1                5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                       5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nruntime-22.2-py3.10-xc           5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base\nautoai-kb_3.1-py3.7              632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8           634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\nspark-mllib_2.3-r_3.6            6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\ntensorflow_2.4-py3.7             65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\nspss-modeler_18.2                687eddc9-028a-4117-b9dd-e57b36f1efa5  base\npytorch-onnx_1.2-py3.6           692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\nspark-mllib_2.3-scala_2.11       7963efe5-bbec-417e-92cf-0574e21b4e8d  base\nspark-mllib_2.4-py37             7abc992b-b685-532b-a122-a396a3cdbaab  base\ncaffe_1.0-py3.6                  7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\npytorch-onnx_1.7-py3.7           812c6631-42b7-5613-982b-02098e6c909c  base\ncuda-py3.6                       82c79ece-4d12-40e6-8787-a7b9e0f62770  base\ntensorflow_1.15-py3.6-horovod    8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\nhybrid_0.1                       8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\npytorch-onnx_1.3-py3.7           8d5d8a87-a912-54cf-81ec-3914adaa988d  base\ncaffe-ibm_1.0-py3.6              8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\nruntime-22.2-py3.10-cuda         8ef391e4-ef58-5d46-b078-a82c211c1058  base\nspss-modeler_17.1                902d0051-84bd-4af6-ab6b-8f6aa6fdeabb  base\ndo_12.10                         9100fd72-8159-4eb9-8a0b-a87e12eefa36  base\ndo_py3.7                         9447fa8b-2051-4d24-9eef-5acb0e3c59f8  base\nspark-mllib_3.0-r_3.6            94bb6052-c837-589d-83f1-f4142f219e32  base\ncuda-py3.7-opence                94e9652b-7f2d-59d5-ba5a-23a414ea488f  base\nnlp-py3.8                        96e60351-99d4-5a1c-9cc0-473ac1b5a864  base\ncuda-py3.7                       9a44990c-1aa1-4c7d-baf8-c4099011741c  base\nhybrid_0.2                       9b3f9040-9cee-4ead-8d7a-780600f542f7  base\nspark-mllib_3.0-py38             9f7a8fc1-4d3c-5e65-ab90-41fa8de2d418  base\nautoai-kb_3.3-py3.7              a545cca3-02df-5c61-9e88-998b09dc79af  base\nspark-mllib_3.0-py39             a6082a27-5acc-5163-b02c-6b96916eb5e0  base\nruntime-22.1-py3.9-do            a7e7dbf1-1d03-5544-994d-e5ec845ce99a  base\ndefault_py3.8                    ab9e1b80-f2ce-592c-a7d2-4f2344f77194  base\ntensorflow_rt22.1-py3.9          acd9c798-6974-5d2f-a657-ce06e986df4d  base\nkernel-spark3.2-py3.9            ad7033ee-794e-58cf-812e-a95f4b64b207  base\nautoai-obm_2.0 with Spark 3.0    af10f35f-69fa-5d66-9bf5-acb58434263a  base\nruntime-22.2-py3.10              b56101f1-309d-549b-a849-eaa63f77b2fb  base\ndefault_py3.7_opence             c2057dd4-f42c-5f77-a02f-72bdbd3282c9  base\ntensorflow_2.1-py3.7             c4032338-2a40-500a-beef-b01ab2667e27  base\ndo_py3.7_opence                  cc8f8976-b74a-551a-bb66-6377f8d865b4  base\nspark-mllib_3.3                  d11f2434-4fc7-58b7-8a62-755da64fdaf8  base\nautoai-kb_3.0-py3.6              d139f196-e04b-5d8b-9140-9a10ca1fa91a  base\nspark-mllib_3.0-py36             d82546d5-dd78-5fbb-9131-2ec309bc56ed  base\nautoai-kb_3.4-py3.8              da9b39c3-758c-5a4f-9cfd-457dd4d8c395  base\nkernel-spark3.2-r3.6             db2fe4d6-d641-5d05-9972-73c654c60e0a  base\nautoai-kb_rt22.1-py3.9           db6afe93-665f-5910-b117-d879897404d9  base\ntensorflow_rt22.1-py3.9-horovod  dda170cc-ca67-5da7-9b7a-cf84c6987fae  base\nautoai-ts_1.0-py3.7              deef04f0-0c42-5147-9711-89f9904299db  base\ntensorflow_2.1-py3.7-horovod     e384fce5-fdd1-53f8-bc71-11326c9c635f  base\ndefault_py3.7                    e4429883-c883-42b6-87a8-f419d64088cd  base\ndo_22.1                          e51999ba-6452-5f1f-8287-17228b88b652  base\nautoai-obm_3.2                   eae86aab-da30-5229-a6a6-1d0d4e368983  base\nruntime-22.2-r4.2                ec0a3d28-08f7-556c-9674-ca7c2dba30bd  base\ntensorflow_rt22.2-py3.10         f65bd165-f057-55de-b5cb-f97cf2c0f393  base\ndo_20.1                          f686cdd9-7904-5f9d-a732-01b0d6b10dc5  base\npytorch-onnx_rt22.2-py3.10-edt   f8a05d07-e7cd-57bb-a10b-23f1d4b837ac  base\nscikit-learn_0.19-py3.6          f963fa9d-4bb7-5652-9c5d-8d9289ef6ad9  base\ntensorflow_2.4-py3.8             fe185c44-9a99-5425-986b-59bd1d2eda46  base\n-------------------------------  ------------------------------------  ----\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\nsoftware_spec_uid", "execution_count": 56, "outputs": [{"output_type": "execute_result", "execution_count": 56, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#store the model\nmodel_details = client.repository.store_model(model='image.Classification.model_new.tgz',meta_props={\n    client.repository.ModelMetaNames.NAME: \"CNN\",\n    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n})\nmodel_id = client.repository.get_model_uid(model_details)", "execution_count": 57, "outputs": [{"output_type": "stream", "text": "This method is deprecated, please use get_model_id()\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/repository.py:1453: UserWarning: This method is deprecated, please use get_model_id()\n  warn(\"This method is deprecated, please use get_model_id()\")\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 58, "outputs": [{"output_type": "execute_result", "execution_count": 58, "data": {"text/plain": "'d08112e3-633c-4efd-818e-efd190310ed7'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,\"my_model.tar.gz\")", "execution_count": 64, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'my_model.tar.gz'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 64, "data": {"text/plain": "'/home/wsuser/work/my_model.tar.gz'"}, "metadata": {}}]}, {"metadata": {"id": "jkYAy2OkB8Z7"}, "cell_type": "code", "source": "from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image", "execution_count": 65, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 62, "outputs": [{"output_type": "execute_result", "execution_count": 62, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"id": "Fxuo9-pFB8dV"}, "cell_type": "code", "source": "model = load_model('aslpng1.h5')", "execution_count": 66, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='jo4gIWjPHHhcIDJdqWh9bGhNZUev1BSftWVW5f8TxCix',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'aicode-donotdelete-pr-zp35pf5y2lzdrf'\nobject_key = 'C.jpg'\n\nstreaming_body_6 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 110, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "img=image.load_img(r\"/home/wsuser/work/Dataset/test_set/A/100.png\")", "execution_count": 111, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "img", "execution_count": 112, "outputs": [{"output_type": "execute_result", "execution_count": 112, "data": {"text/plain": "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FB614F01580>", "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAACH0lEQVR4nO2aPY7CMBCFJ4kQLYgGGmq4AWegoEWipqCgouIISBwAbhBugDgBJT0FlKGEyogEsgVabbS7CXhm/KNdf2XkSd6TZxzHEwCHw+FwOP406SeLxcK0ll/wXo5I0/RrtPd6vGZ8qdFZM5YgZ8BC/p8BIQQARFH0rOwoihSo4iMMw/QNhBBxHH+7eL1eAUAIkb2YJAmvwheriraq9X0f96yiFNK58D8eD9/HFGTRDGheNJMkKZVKslG5ppvNJk2PNJfLBRGVa2A+nxPEYIjjGBGVm0L6X7rn87larcpG5c7Abrej6ZGm3W4jonINbDYbghgMp9MJEWXRKgSo3a5deyHOZdQIQRDIhrgUMo1FBnCrkEUGcLgaMI1FBhqNBiKqyMByucSKwYD7vC4ycDwesWKsYTqdvvNRz4KqA471eq3NgxIDALDdbjWor9frqgwAwGQyUW1Aofon4/FYnfpWq6XcAAAMh0NFBsIw1GEAMv0OXrrdLk6P9JvY87zBYIB7WAGHw4H9nkWwz4CmGsjS7/cZDaBlkHpe5XL5eYZOB919ozbtgiBgOfJHG6Bup+/3+2g0It7kdruhY3nappQkBlr31ooPmk6ng451MwAAAPv9nuU+xuj1epSXAMU/278PprLIiiKmwGZgNptRwg3shX5CKQO0AZdCGTQfhCmBkkW1Wg3xRItSCNEg44cyA/xnowhWqxU6tlKpIKI+ALi4CJLPHAFLAAAAAElFTkSuQmCC\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing import image\nimg = image.load_img(r\"/home/wsuser/work/Dataset/test_set/A/100.png\",target_size = (100,100))\nimg", "execution_count": 134, "outputs": [{"output_type": "execute_result", "execution_count": 134, "data": {"text/plain": "<PIL.Image.Image image mode=RGB size=100x100 at 0x7FB4B468F820>", "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAADCUlEQVR4nO2csW7iQBCGx/istIlEQRpq5w3yCEiR0iJSU1BQUfEISCh1LOUBkicgyhOkTBtROKVpkKAyig2+wlKU3OlOHjKza6/+r6Iws+Nf8w+73jVEAAAAAAAAAAAAAHWh+M7d3Z3tjAzRsp1Ak/CO+E5RFH9G8Y6J0zhkKqv0o0ioOgMbMoBYDCAWA4jFQFKsNE3TNCWiJEmSJPmciCVJIjhKk3h4eCiOJU3TLMuyLPvXBbvdrhyl1P3vC/I8t3jvsCED9mSy/vOpVqtFOnmishj8qn5pUxbMh8OBiHzfLz8IwrBh/Q34lTzPgyCQjQkbMqgqVrfbVc1DnO12Kx6zqljz+Vx8bFWyLBOPCRsyqNrgm9XdiWiz2ZydncnGrFpZr6+vsgNrc3FxIR4TNmRQVazn52fVPMRZrVbiMZ2dlJLCNgpsyMBlsYIgkF3xuCyWOC6L5fu+7/uCAdHgGbhcWeJALAbOiqUxKXVWLA0gFgP8GjJAZTGAWAwgFgNnxTo/PxePyWiB5Y70aDQST0IJNHibMM46vL+/6+XhJtPp9OjDbCbROG4IGzI4pgU+PT0RUa/Xk05GmBq99/Hy8mLbav+j0+mI3zJsyOBHhTqZTIjo9vZWKBlJauTBr4zHY9ue+0YYhmEYatwpbMhAplaHwyER3d/fi0T7IY+Pj0Q0GAzEI6OyGEh2waIej1Kvrq6IaLFYiEeWrCzP8zzPu7m5EYx5BHEcx3GsERk2ZKAyGbHrx/KA5Nvbm8Uc2PT7fSvzLL07gg0Z6K4JTk5OiOjzlUsz6C10TCygfN83+QaqnliwIQMTYu33+9FoZGZb6OPjQy84KouB0Yc+BuZfqo+xXKusy8tLveCuiaUKbMjAaGUtl0uTw4kDG9aV6+tr7VW0avGa3i9qdNuCDRlALAamxZrNZrPZTHUIbLLWAjsHAlTbvN4zeFQWA4jFwI5YURRFUWRl6J+AymJg88SXaptvt9vr9Vo2prOVJf4fduSwWBo4K5bGf1jZFKs8oqfE6empeExnK0uD34rK5FYs3uJnAAAAAElFTkSuQmCC\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from skimage.transform import resize\ndef detect(frame):\n  img=image.img_to_array(frame)\n  img = resize(frame, (64,64,1))\n  img = np.expand_dims(img, axis = 0)\n  pred=np.argmax(model.predict(img))\n  op=['A','B','C','D','E','F','G','H','I']\n  print('The predicted letter is',op[pred])", "execution_count": 135, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import sys\nsys.setrecursionlimit(1500)", "execution_count": 136, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install opencv-python\nimport cv2\nframe = cv2.imread(r'/home/wsuser/work/Dataset/test_set/A/100.png')\ndata = detect(frame)", "execution_count": 141, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: opencv-python in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (4.6.0.66)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from opencv-python) (1.19.5)\n", "name": "stdout"}, {"output_type": "error", "ename": "ImportError", "evalue": "libGL.so.1: cannot open shared object file: No such file or directory", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_1790/2613495996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install opencv-python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/home/wsuser/work/Dataset/test_set/A/100.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory"]}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 117, "outputs": [{"output_type": "stream", "text": "100.png  126.png  151.png  177.png  201.png  227.png  26.png  51.png  77.png\r\n101.png  127.png  152.png  178.png  202.png  228.png  27.png  52.png  78.png\r\n102.png  128.png  153.png  179.png  203.png  229.png  28.png  53.png  79.png\r\n103.png  129.png  154.png  17.png   204.png  22.png   29.png  54.png  7.png\r\n104.png  12.png   155.png  180.png  205.png  230.png  2.png   55.png  80.png\r\n105.png  130.png  156.png  181.png  206.png  231.png  30.png  56.png  81.png\r\n106.png  131.png  157.png  182.png  207.png  232.png  31.png  57.png  82.png\r\n107.png  132.png  158.png  183.png  208.png  233.png  32.png  58.png  83.png\r\n108.png  133.png  159.png  184.png  209.png  234.png  33.png  59.png  84.png\r\n109.png  134.png  15.png   185.png  20.png   235.png  34.png  5.png   85.png\r\n10.png   135.png  160.png  186.png  210.png  236.png  35.png  60.png  86.png\r\n110.png  136.png  161.png  187.png  211.png  237.png  36.png  61.png  87.png\r\n111.png  137.png  162.png  188.png  212.png  238.png  37.png  62.png  88.png\r\n112.png  138.png  163.png  189.png  213.png  239.png  38.png  63.png  89.png\r\n113.png  139.png  164.png  18.png   214.png  23.png   39.png  64.png  8.png\r\n114.png  13.png   165.png  190.png  215.png  240.png  3.png   65.png  90.png\r\n115.png  140.png  166.png  191.png  216.png  241.png  40.png  66.png  91.png\r\n116.png  141.png  167.png  192.png  217.png  242.png  41.png  67.png  92.png\r\n117.png  142.png  168.png  193.png  218.png  243.png  42.png  68.png  93.png\r\n118.png  143.png  169.png  194.png  219.png  244.png  43.png  69.png  94.png\r\n119.png  144.png  16.png   195.png  21.png   245.png  44.png  6.png   95.png\r\n11.png   145.png  170.png  196.png  220.png  246.png  45.png  70.png  96.png\r\n120.png  146.png  171.png  197.png  221.png  247.png  46.png  71.png  97.png\r\n121.png  147.png  172.png  198.png  222.png  248.png  47.png  72.png  98.png\r\n122.png  148.png  173.png  199.png  223.png  249.png  48.png  73.png  99.png\r\n123.png  149.png  174.png  19.png   224.png  24.png   49.png  74.png  9.png\r\n124.png  14.png   175.png  1.png    225.png  250.png  4.png   75.png\r\n125.png  150.png  176.png  200.png  226.png  25.png   50.png  76.png\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 80, "outputs": [{"output_type": "stream", "text": "100.png  126.png  151.png  177.png  201.png  227.png  26.png  51.png  77.png\r\n101.png  127.png  152.png  178.png  202.png  228.png  27.png  52.png  78.png\r\n102.png  128.png  153.png  179.png  203.png  229.png  28.png  53.png  79.png\r\n103.png  129.png  154.png  17.png   204.png  22.png   29.png  54.png  7.png\r\n104.png  12.png   155.png  180.png  205.png  230.png  2.png   55.png  80.png\r\n105.png  130.png  156.png  181.png  206.png  231.png  30.png  56.png  81.png\r\n106.png  131.png  157.png  182.png  207.png  232.png  31.png  57.png  82.png\r\n107.png  132.png  158.png  183.png  208.png  233.png  32.png  58.png  83.png\r\n108.png  133.png  159.png  184.png  209.png  234.png  33.png  59.png  84.png\r\n109.png  134.png  15.png   185.png  20.png   235.png  34.png  5.png   85.png\r\n10.png   135.png  160.png  186.png  210.png  236.png  35.png  60.png  86.png\r\n110.png  136.png  161.png  187.png  211.png  237.png  36.png  61.png  87.png\r\n111.png  137.png  162.png  188.png  212.png  238.png  37.png  62.png  88.png\r\n112.png  138.png  163.png  189.png  213.png  239.png  38.png  63.png  89.png\r\n113.png  139.png  164.png  18.png   214.png  23.png   39.png  64.png  8.png\r\n114.png  13.png   165.png  190.png  215.png  240.png  3.png   65.png  90.png\r\n115.png  140.png  166.png  191.png  216.png  241.png  40.png  66.png  91.png\r\n116.png  141.png  167.png  192.png  217.png  242.png  41.png  67.png  92.png\r\n117.png  142.png  168.png  193.png  218.png  243.png  42.png  68.png  93.png\r\n118.png  143.png  169.png  194.png  219.png  244.png  43.png  69.png  94.png\r\n119.png  144.png  16.png   195.png  21.png   245.png  44.png  6.png   95.png\r\n11.png   145.png  170.png  196.png  220.png  246.png  45.png  70.png  96.png\r\n120.png  146.png  171.png  197.png  221.png  247.png  46.png  71.png  97.png\r\n121.png  147.png  172.png  198.png  222.png  248.png  47.png  72.png  98.png\r\n122.png  148.png  173.png  199.png  223.png  249.png  48.png  73.png  99.png\r\n123.png  149.png  174.png  19.png   224.png  24.png   49.png  74.png  9.png\r\n124.png  14.png   175.png  1.png    225.png  250.png  4.png   75.png\r\n125.png  150.png  176.png  200.png  226.png  25.png   50.png  76.png\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "img2=image.load_img(r\"/home/wsuser/work/Dataset/test_set/C/102.png\")", "execution_count": 118, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "img2", "execution_count": 119, "outputs": [{"output_type": "execute_result", "execution_count": 119, "data": {"text/plain": "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FB6153EDF10>", "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAACpUlEQVR4nO2Zv6rqQBDGdw8YDVoIPoAgCBF7TRUbC7FIa+wEC30MOx8hClY2prfwASxSCKKFoKWVjZ1iooh7iwXvOdF7TTaTPwfyqwxkZufb2W+TjQhFREREREREBAcGzNVut6vV6vNSURT6YzgcdrtdwIFgmM1mxDZBF/sTXdftl/5E1/WgC0dotVoxlB6KPsznczelPxkMBrCF2TUx4PxhDLlzfNm8D1AAIaTf70Nlsytgt9tBDYkQSqVSgNk+k81mQQxgwT8Bp9PJCwGdTsc/DV4IIITUajX/NEwmEy80ABraFrFYTFXVXq+HECoWi1Ay0um0rzK+Uy6X386iUw3+V/6Bw+HggwbIh+IrTmvied40TUchdh9k/jAej4Mu4SeGYThdRYZhOBrC2w7wPO9pfuS1B5BzGxBCvr4cTGu4PIAQwhg70hw6AZR4PG7zzpAKWK/XQZeAEGLahZ5kMhk7Q9jqgCAIHMcxCEgkEgxRlMvlwhz7l3w+/31WJEkqlUr2w5mnn+K2elVV3+a1+RLP8C5kYbFYfByFxcT0m5yiKJVK5T+3uVk/lOPx6Cr+Xx2wIEnSa6z76aeMRiNXGprNJkgdbnAlgLLf7wMUsFwuATQ0Go0ANQAIoASoQZbltyU524VgP2s6olAoQKYTRdH/JnjyD4MgCH5qqNfrlgJglkQymTyfzyCpPmJZxpBrOpFIOD3RMmARAHkeME0TYzydTgFzvkIIEUXxeQl/oJFlGWN8v9/BMwfA4/HwyM25XI4O4fm+znHc9Xr1IjM1g+dn4tvthjH24glID/7+HeoxxpqmaZoGlbDVakGlYmSz2bh0AvLBAx8hLl42McbBfxdyaY/gO0Bh7kPwHXBJWARst1u2wLAIYObXCwiLiRGrj399B/4ATgtRai762g8AAAAASUVORK5CYII=\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "x=image.img_to_array(img)", "execution_count": 120, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x", "execution_count": 121, "outputs": [{"output_type": "execute_result", "execution_count": 121, "data": {"text/plain": "array([[[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "x=np.expand_dims(x,axis=1)", "execution_count": 122, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x", "execution_count": 123, "outputs": [{"output_type": "execute_result", "execution_count": 123, "data": {"text/plain": "array([[[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]],\n\n\n       [[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]],\n\n\n       [[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]],\n\n\n       ...,\n\n\n       [[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]],\n\n\n       [[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]],\n\n\n       [[[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.],\n         ...,\n         [0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "y=np.argmax(model.predict(x),axis=0)", "execution_count": 133, "outputs": [{"output_type": "error", "ename": "ValueError", "evalue": "in user code:\n\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:251 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape (32, 1, 64, 3)\n", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_1790/1855069758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3440\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3441\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3360\u001b[0m           expand_composites=True)\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3362\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3363\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:251 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape (32, 1, 64, 3)\n"]}]}, {"metadata": {}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 128, "outputs": [{"output_type": "execute_result", "execution_count": 128, "data": {"text/plain": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "index=['A','B','C','D','E','F','G','H','I']", "execution_count": 129, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "index[y[0]]", "execution_count": 130, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'y' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_1790/779991614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "from skimage.transform import resize\ndef detect(frame):\n  img=image.img_to_array(frame)\n  img = resize(frame, (64,64,1))\n  img = np.expand_dims(img, axis = 0)\n  pred=np.argmax(model.predict(img))\n  op=['A','B','C','D','E','F','G','H','I']\n  print('The predicted letter is',op[pred])", "execution_count": 106, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import sys\nsys.setrecursionlimit(1500)", "execution_count": 107, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "frame = cv2.imread(r'/home/wsuser/work/Dataset/test_set/A/100.png')\ndata = detect(frame)", "execution_count": 108, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'cv2' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_1790/1691991778.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/home/wsuser/work/Dataset/test_set/A/100.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}]}], "metadata": {"colab": {"collapsed_sections": [], "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}